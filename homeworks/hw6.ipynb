{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZXJoDiD_x-N"
   },
   "source": [
    "# Homework6: Denoising Diffusion generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxF8ewFXn1HO",
    "tags": []
   },
   "source": [
    "## Task 1: Theory (4pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWkz0w2_haMk"
   },
   "source": [
    "### Problem 1: Faster sampling with DDPM (spaced diffusion) (1pt)\n",
    "\n",
    "Sampling from DDPM is very slow. In the practical part of HW you will see that it took about 8 seconds to generate a batch of images with our diffusion model (even using a gpu).\n",
    "While, as you might remember, it took less than a second using other generative models (VAE/GAN/NF).\n",
    "This drawback can't be solved generally with using more gpus, since it requires iterative sampling.\n",
    "There are several techniques to alleviate this drawback. In this task We are going to investigate one of them.\n",
    "\n",
    "Assume we have already trained a model $p(\\mathbf{x}_{t - 1} | \\mathbf{x}_t, \\boldsymbol{\\theta})$ to \"reverse\" a Markov chain of length $T$.\n",
    "\n",
    "Let try to build inference process using subsequence of timesteps\n",
    "$\\{S_0 = 0, S_1, \\ldots, S_{T'-1}, S_{T'} = T\\}$, where $T' < T$.\n",
    "\n",
    "Using this subsequence we have to do $T' (< T)$ inference steps instead of $T$. It could dramatically reduce inference time.\n",
    "\n",
    "Diffusion models inference are essentially defined by\n",
    "- schedule of variances $\\{\\beta_1, \\ldots, \\beta_T\\}$\n",
    "- reverse process:\n",
    "$$\n",
    "p(\\mathbf{x}_{S_{t - 1}} | \\mathbf{x}_{S_t}, \\boldsymbol{\\theta}) = \\mathcal{N} \\bigl(\\mathbf{x}_{S_{t - 1}} | \\boldsymbol{\\mu}_{\\boldsymbol{\\theta}, S_t}(\\mathbf{x}_{S_t}), \\tilde{\\beta}_{S_t}\\bigr)\n",
    "$$\n",
    "\n",
    "Therefore, all you have to find is the variances for the new Markov chain: $\\{\\tilde{\\beta}_{S_1}, \\ldots, \\tilde{\\beta}_{S_{T'}}\\}$.\n",
    "\n",
    "**Task:** find the expression for $\\tilde{\\beta}_{S_t}$ (it should depend on $\\alpha$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVsqN1O3uk6x"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Classifier guidance (1pt)\n",
    "\n",
    "Consider the label distribution $p(\\mathbf{y} | \\mathbf{x})$. Assume that we are given the guidance scale $\\gamma > 1$.\n",
    "\n",
    "As we discussed at Lecture 12 the guidance scale sharpens the label distribution:\n",
    "$$\n",
    "    \\hat{p}(\\mathbf{y} | \\mathbf{x}) \\propto p(\\mathbf{y} | \\mathbf{x})^\\gamma.\n",
    "$$\n",
    "\n",
    "In this case conditional distribution equals to\n",
    "$$\n",
    "     p(\\mathbf{x} | \\mathbf{y}, \\boldsymbol{\\theta}) = \\frac{\\hat{p}(\\mathbf{y} | \\mathbf{x}) p(\\mathbf{x} | \\boldsymbol{\\theta})}{\\hat{p}(\\mathbf{y})}.\n",
    "$$\n",
    "\n",
    "Find the expression for $\\nabla_{\\mathbf{x}} \\log p(\\mathbf{x} | \\mathbf{y}, \\boldsymbol{\\theta})$ in terms of the initial label distribution $p(\\mathbf{y} | \\mathbf{x})$.\n",
    "\n",
    "You have to see that strictly speaking \n",
    "$$\n",
    "     \\nabla_{\\mathbf{x}} \\log p(\\mathbf{x} | \\mathbf{y}, \\boldsymbol{\\theta}) \\neq \\gamma \\cdot \\nabla_{\\mathbf{x}} \\log p(\\mathbf{y} | \\mathbf{x}) + \\nabla_{\\mathbf{x}} \\log p(\\mathbf{x} | \\boldsymbol{\\theta}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFn6d3vkuZIl"
   },
   "source": [
    "### Problem 3: KFP theorem (2pt)\n",
    "\n",
    "In Lecture 13 we have faced with 2 different formulations of Kolmogorov-Fokker-Planck theorem.\n",
    "\n",
    "1) We used the following KFP theorem when we discussed continuous-in-time NF:\n",
    "$$\n",
    "\\frac{d \\log p(\\mathbf{x}(t), t)}{d t} = - \\text{tr} \\left( \\frac{\\partial f(\\mathbf{x}, t)}{\\partial \\mathbf{x}} \\right).\n",
    "$$\n",
    "\n",
    "2) We used the following KFP theorem when we discussed SDEs:\n",
    "$$\n",
    "\\frac{\\partial p(\\mathbf{x}, t)}{\\partial t} = \\text{tr}\\left(- \\frac{\\partial}{\\partial \\mathbf{x}} \\bigl[ \\mathbf{f}(\\mathbf{x}, t) p(\\mathbf{x}, t)\\bigr] + \\frac{1}{2} g^2(t) \\frac{\\partial^2 p(\\mathbf{x}, t)}{\\partial \\mathbf{x}^2} \\right)\n",
    "$$\n",
    "\n",
    "In this task your goal is to prove that the first formulation is a special case of the more general second formulation.\n",
    "\n",
    "You have to use two facts:\n",
    "1) Continuous-in-time NF use ODE (not SDE).\n",
    "2) The derivation in the first formulation is total derivative (not partial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbxPyzwcuinj"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41370,
     "status": "ok",
     "timestamp": 1700068971438,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "nYZ__zsi3McN",
    "outputId": "1153bb7c-f9cd-4a0f-83bd-e2827f989f53"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown\n",
    "\n",
    "COMMIT_HASH = \"b4df45506b5dc4cd055cb00facebc504fd57571a\"\n",
    "!if [ -d dgm_utils ]; then rm -Rf dgm_utils; fi\n",
    "!git clone https://github.com/r-isachenko/dgm_utils.git\n",
    "%cd dgm_utils\n",
    "!git checkout {COMMIT_HASH}\n",
    "!pip install ./\n",
    "%cd ./..\n",
    "!rm -Rf dgm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mC57wAo5Yag"
   },
   "outputs": [],
   "source": [
    "import dgm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1700068977911,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "grmP96FjfQZg",
    "outputId": "19c07923-08ff-45a4-e607-34e3c5bc325e"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRFti0_GCRpD"
   },
   "source": [
    "## Task 2: DDPM for 2D data (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8vx6pxgCqBv"
   },
   "source": [
    "In this part you have to implement your own diffusion model (DDPM) and apply it to 2D dataset.\n",
    "\n",
    "Let's take a look at dataset samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wbzR9hw2F06"
   },
   "outputs": [],
   "source": [
    "def generate_moons_data(count: int) -> tuple:\n",
    "    data, labels = make_moons(n_samples=count, noise=0.1)\n",
    "    data = data.astype(\"float32\")\n",
    "    split = int(0.8 * count)\n",
    "    train_data, test_data = data[:split], data[split:]\n",
    "    train_labels, test_labels = labels[:split], labels[split:]\n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3U4b0HQ2F06",
    "outputId": "a3d8dfdd-0e64-4f51-a1eb-c6346c7ca01c"
   },
   "outputs": [],
   "source": [
    "COUNT = 5000\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = generate_moons_data(COUNT)\n",
    "dgm_utils.visualize_2d_data(train_data, test_data, train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRqWAIRmQDQ8"
   },
   "source": [
    "Below you see the utility function, which broadcasts tensors. Look carefully at this code, we will use it in the majority of methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VwXNzi6fQZm"
   },
   "outputs": [],
   "source": [
    "def _extract_into_tensor(arr, indices, broadcast_shape):\n",
    "    \"\"\"\n",
    "    Extract values from a 1-D torch tensor for a batch of indices.\n",
    "    :param arr: 1-D torch tensor.\n",
    "    :param timesteps: a tensor of indices to extract from arr.\n",
    "    :param broadcast_shape: a larger shape of K dimensions with the batch\n",
    "                            dimension equal to the length of timesteps.\n",
    "    :return: a tensor of shape [batch_size, 1, ...] where the shape has K dims.\n",
    "    \"\"\"\n",
    "    assert len(arr.shape) == 1\n",
    "    res = arr.to(device=indices.device)[indices].float()\n",
    "    while len(res.shape) < len(broadcast_shape):\n",
    "        res = res[..., None]\n",
    "\n",
    "\n",
    "    return res.expand(broadcast_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JGW21W32F07"
   },
   "source": [
    "### Forward Diffusion\n",
    "\n",
    "Let start with forward diffusion.\n",
    "\n",
    "**Forward process** is defined as a posterior distribution $q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)$.\n",
    "\n",
    "It is a Markov chain, which consequently adds gaussian noise to a given object $\\mathbf{x}_0$.\n",
    "\n",
    "At every step of this process the gaussian noise is added with different magnitude, which is determined with a schedule of variances $\\{\\beta_1, ... \\beta_T\\}$.\n",
    "If this schedule is chosen properly and T goes to infinity (or is large enough), we will converge to pure noise $\\mathcal{N}(0, I)$.\n",
    "\n",
    "Markov chain is defined by:\n",
    "$$\n",
    " q(\\mathbf{x}_t | \\mathbf{x}_{t - 1}) = \\mathcal{N}(\\mathbf{x}_t | \\sqrt{1 - \\beta_t}\\mathbf{x}_{t - 1}, \\beta_t \\mathbf{I}), \\quad q(\\mathbf{x}_{1:T}|\\mathbf{x}_0) = \\prod_{t = 1}^T q(\\mathbf{x}_t | \\mathbf{x}_{t - 1})\n",
    "$$\n",
    "\n",
    "In order to get $\\mathbf{x}_t$ we have to compute $\\mathbf{x}_1, ..., \\mathbf{x}_{t - 1}$ iteratively.\n",
    "\n",
    "Hopefully, due to the properties of the gaussian distribution we can do it more efficiently.\n",
    "\n",
    "Let's denote\n",
    "$\\alpha_t = 1- \\beta_t$ и $\\bar{\\alpha}_t= \\prod_{s = 1}^t\\alpha_s$.\n",
    "Then\n",
    "$$\n",
    "q(\\mathbf{x}_t | \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t|\\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1-\\bar{\\alpha}_t) \\mathbf{I}).\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "Here we could get very useful expression\n",
    "$$\n",
    "    \\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1-\\bar{\\alpha}_t} \\cdot \\boldsymbol{\\epsilon}. \\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usjLZY1-2F07"
   },
   "source": [
    "Now we will create base class for diffusion (we will use it as a python base class for forward and backward diffusions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPgOkluQ2F07",
    "outputId": "bf60783a-31cc-4254-ec20-ca747ecd844f"
   },
   "outputs": [],
   "source": [
    "class BaseDiffusion:\n",
    "    def __init__(self, num_timesteps: int):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.betas = self._get_beta_schedule(num_timesteps)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=-1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_beta_schedule(num_diffusion_timesteps, s=0.008):\n",
    "        def f(t, T):\n",
    "            return (np.cos((t / T + s) / (1 + s) * np.pi / 2)) ** 2\n",
    "\n",
    "        alphas = []\n",
    "        f0 = f(0, num_diffusion_timesteps)\n",
    "\n",
    "        for t in range(num_diffusion_timesteps + 1):\n",
    "            alphas.append(f(t, num_diffusion_timesteps) / f0)\n",
    "\n",
    "        betas = []\n",
    "\n",
    "        for t in range(1, num_diffusion_timesteps + 1):\n",
    "            betas.append(min(1 - alphas[t] / alphas[t - 1], 0.999))\n",
    "\n",
    "        return torch.from_numpy(np.array(betas)).double()\n",
    "\n",
    "\n",
    "basediff = BaseDiffusion(num_timesteps=20)\n",
    "\n",
    "plt.plot(basediff.betas.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrGZqa5A2F07"
   },
   "source": [
    "We are ready to define forward diffusion process. It has 2 methods:\n",
    "- to get mean and variance of the distribution $q(\\mathbf{x}_t | \\mathbf{x}_0)$,\n",
    "- to get samples from this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3X5Gm1aC3zc"
   },
   "outputs": [],
   "source": [
    "class ForwardDiffusion(BaseDiffusion):\n",
    "    def get_mean_variance(self, x0, t):\n",
    "        # ====\n",
    "        # your code\n",
    "        # calculate mean and variance of the distribution q(x_t | x_0) (use equation (1))\n",
    "        # use _extract_into_tensor() function to get tensors of the same shape as x0\n",
    "        mean = \n",
    "        variance = \n",
    "        # ====\n",
    "        return mean, variance\n",
    "\n",
    "    def get_samples(self, x0, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        # ====\n",
    "        # your code\n",
    "        # sample from the distribution q(x_t | x_0) (use equation (2))\n",
    "        \n",
    "        # ====\n",
    "        return samples\n",
    "\n",
    "\n",
    "def test_forward_diffusion():\n",
    "    fdiff = ForwardDiffusion(num_timesteps=100)\n",
    "    SHAPE = [2, 20]\n",
    "    x0 = torch.ones(SHAPE)\n",
    "    t = torch.ones((2,)).long() * 5\n",
    "    mean, variance = fdiff.get_mean_variance(x0=x0, t=t)\n",
    "    assert list(mean.shape) == SHAPE\n",
    "    assert list(variance.shape) == SHAPE\n",
    "    assert np.allclose(mean.numpy(), np.ones(SHAPE) * 0.9944681)\n",
    "    assert np.allclose(variance.numpy(), np.ones(SHAPE) * 0.01103322)\n",
    "\n",
    "    xt = fdiff.get_samples(x0=x0, t=t)\n",
    "    assert list(xt.shape) == SHAPE\n",
    "\n",
    "    noise = torch.ones(SHAPE)\n",
    "    xt = fdiff.get_samples(x0=x0, t=t, noise=noise)\n",
    "    assert np.allclose(xt.numpy(), np.ones(SHAPE) * 1.0995072)\n",
    "\n",
    "\n",
    "test_forward_diffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDF9k0r32F07"
   },
   "source": [
    "Let visualize the forward diffusion process. Here you have to see how the distribution of the real samples transforms to the gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3hgwOcGfQZo",
    "outputId": "dfb27928-bf61-45e3-9453-fe1be2dacc18"
   },
   "outputs": [],
   "source": [
    "T = 100\n",
    "\n",
    "fdiff = ForwardDiffusion(num_timesteps=T)\n",
    "\n",
    "timestamps=[0, 2, 4, 10, 50]\n",
    "\n",
    "plot_n_steps = len(timestamps)\n",
    "for i, t in enumerate(timestamps):\n",
    "    x = fdiff.get_samples(x0=torch.from_numpy(train_data), t=torch.ones((train_data.shape[0], 1)).long() * t)\n",
    "    dgm_utils.visualize_2d_samples(x, title=f\"Step of diffusion: {t}\", labels=train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVEnKClW2F08"
   },
   "source": [
    "### Reverse Diffusion\n",
    "\n",
    "**Reverse process** consequently denoises pure gaussian noise $\\mathcal{N}(0, \\mathbf{I})$ until we do not get the object from the original distribution $\\pi(\\mathbf{x})$.\n",
    "\n",
    "It is a probability model with latent variables\n",
    "$p(\\mathbf{x}_0 | \\boldsymbol{\\theta}) := \\int p(\\mathbf{x}_{0:T} | \\boldsymbol{\\theta}) d\\mathbf{x}_{1:T}$,\n",
    "where\n",
    "- latents $\\mathbf{z} = \\{\\mathbf{x}_1, ..., \\mathbf{x}_T \\}$ correspond to noised objects\n",
    "- $\\mathbf{x}_0$ is an object from the original distribution $\\pi(\\mathbf{x})$.\n",
    "\n",
    "Joint distribution $p(\\mathbf{x}_{0:T} | \\boldsymbol{\\theta})$ is called reverse diffusion process, which is essentially a Markov chain of gaussian distributions $p(\\mathbf{x}_t|\\mathbf{x}_t, \\boldsymbol{\\theta})$:\n",
    "$$\n",
    "p(\\mathbf{x}_{0:T}) = p(\\mathbf{x}_T) \\prod_{t = 1}^T p(\\mathbf{x}_{t-1}|\\mathbf{x}_t, \\boldsymbol{\\theta}), \\quad p(\\mathbf{x}_{T} | \\boldsymbol{\\theta})=\\mathcal{N}(0, \\mathbf{I})\n",
    "$$\n",
    "$$\n",
    "  p(\\mathbf{x}_{t - 1}|\\mathbf{x}_t | \\boldsymbol{\\theta}) = \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t), \\boldsymbol{\\sigma}^2_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t)). \\tag{3}\n",
    "$$\n",
    "\n",
    "In Lecture 11 we have derived ELBO for this model:\n",
    "\n",
    "$$\n",
    "    \\mathcal{L}(q, \\boldsymbol{\\theta}) =  \\mathbb{E}_{q} \\Bigl[\\log p(\\mathbf{x}_0 | \\mathbf{x}_1, \\boldsymbol{\\theta}) - KL\\bigl(q(\\mathbf{x}_T | \\mathbf{x}_0) || p(\\mathbf{x}_T)\\bigr)\n",
    "    - \\sum_{t=2}^T \\underbrace{KL \\bigl(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) || p(\\mathbf{x}_{t - 1} | \\mathbf{x}_t, \\boldsymbol{\\theta} )\\bigr)}_{\\mathcal{L}_t} \\Bigr].\n",
    "$$\n",
    "\n",
    "Here we use the following distribution $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) = \\mathcal{N}( \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0), \\tilde{\\beta}_t \\mathbf{I}) $, where\n",
    "$$\n",
    "\\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0) = \\frac{\\sqrt{\\alpha_t}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} \\mathbf{x}_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1 - \\bar{\\alpha}_t} \\mathbf{x}_0\n",
    "\\tag{4}\n",
    "$$\n",
    "$$\n",
    "\\tilde{\\beta}_t = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\cdot \\beta_t\n",
    "\\tag{5}\n",
    "$$\n",
    "\n",
    "(These scary formulas are not difficult to derive, follow the link to find details [Denoising Diffusion Probabilistic Models (Ho et al. 2020)](https://arxiv.org/abs/2006.11239)).\n",
    "\n",
    "Now our goal is to define parameters $\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t), \\boldsymbol{\\sigma}^2_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t)$ of reverse diffusion.\n",
    "\n",
    "#### Variance\n",
    "Our first assumption is to set the variance $\\boldsymbol{\\sigma}^2_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t) = \\tilde{\\beta}_t$. This is very native assumption\n",
    "\n",
    "#### Mean\n",
    "Here we will use the expression (2) to get $\\mathbf{x}_0$ from $\\mathbf{x}_t$:\n",
    "$$\n",
    "    \\mathbf{x}_0 = \\frac{\\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_{t}} \\cdot \\boldsymbol{\\epsilon}}{\\sqrt{\\bar{\\alpha}_{t}}}.\n",
    "    \\tag{6}\n",
    "$$\n",
    "\n",
    "If we put this expression to the formula (4) we will get:\n",
    "$$\n",
    "    \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\cdot \\boldsymbol{\\epsilon} \\right).\n",
    "$$\n",
    "\n",
    "So the idea here to parametrize the model mean in the same functional form:\n",
    "$$\n",
    "    \\boldsymbol{\\mu}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\cdot \\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t) \\right).\n",
    "$$\n",
    "\n",
    "**Note:** our model will predict the noise which was applied to $\\mathbf{x}_0$ to get $\\mathbf{x}_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Imt4i-zM2F08",
    "outputId": "401299f2-230f-4d74-f085-b6acb266f34c"
   },
   "outputs": [],
   "source": [
    "class ReverseDiffusion(BaseDiffusion):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alphas_cumprod_prev = torch.cat(\n",
    "            [torch.tensor([1.0], device=self.betas.device), self.alphas_cumprod[:-1]], dim=0\n",
    "        )\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # calculate variance of the distribution q(x_{t-1} | x_t, x_0) (use equation (5))\n",
    "        self.variance = \n",
    "        # ====\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # calculate coefficients of mean of the distribution q(x_{t-1} | x_t, x_0) (use equation (4))\n",
    "        # mean = x_coef * x_t + x0_coef * x_0\n",
    "        self.xt_coef = \n",
    "        self.x0_coef = \n",
    "        # ====\n",
    "\n",
    "    def get_x0(self, xt, eps, t):\n",
    "        # ====\n",
    "        # your code\n",
    "        # get x_0 (use equation (6))\n",
    "        \n",
    "        # ====\n",
    "        return x0\n",
    "\n",
    "    def get_mean_variance(self, xt, eps, t):\n",
    "        # ====\n",
    "        # your code\n",
    "        # get mean and variance of the distribution q(x_{t-1} | x_t, x_0) (use equations (4) and (5))\n",
    "        # use get_x0 method to get x_0\n",
    "        \n",
    "        # ====\n",
    "        return mean, variance\n",
    "\n",
    "    def get_samples(self, xt, eps, t):\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) get mean and variance of the distribution q(x_{t-1} | x_t, x_0)\n",
    "        # 2) sample noise from the standard normal \n",
    "        # 3) get samples using reparametrization trick\n",
    "        # ====\n",
    "        return sample.float()\n",
    "\n",
    "\n",
    "def test_reverse_diffusion():\n",
    "    rdiff = ReverseDiffusion(num_timesteps=100)\n",
    "    SHAPE = [2, 20]\n",
    "    xt = torch.ones(SHAPE)\n",
    "    eps = torch.ones(SHAPE)\n",
    "    t = torch.ones((2,)).long() * 5\n",
    "\n",
    "    x0 = rdiff.get_x0(xt=xt, eps=eps, t=t)\n",
    "    assert list(x0.shape) == SHAPE\n",
    "    assert np.allclose(x0.numpy(), np.ones(SHAPE) * 0.8999391)\n",
    "\n",
    "    mean, variance = rdiff.get_mean_variance(xt=xt, eps=eps, t=t)\n",
    "    assert list(mean.shape) == SHAPE\n",
    "    assert list(variance.shape) == SHAPE\n",
    "    assert np.allclose(mean.numpy(), np.ones(SHAPE) * 0.9723116)\n",
    "    assert np.allclose(variance.numpy(), np.ones(SHAPE) * 0.00222036)\n",
    "\n",
    "    x = rdiff.get_samples(xt, eps, t)\n",
    "    assert list(x.shape) == SHAPE\n",
    "\n",
    "\n",
    "test_reverse_diffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJuBzzar2F08"
   },
   "source": [
    "### Model\n",
    "\n",
    "In this task we will use simple MLP model to parametrize distribution $p(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\boldsymbol{\\theta})$. It will be conditioned on the timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CbtFK3NF2F08"
   },
   "outputs": [],
   "source": [
    "class ConditionalMLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, num_embeds: int, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.x_proj = nn.Linear(input_dim, self.hidden_dim)\n",
    "        self.t_proj = nn.Embedding(num_embeds, self.hidden_dim)\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(self.hidden_dim, input_dim),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.x_proj(x)\n",
    "        t = self.t_proj(t.int())\n",
    "        x = x + t\n",
    "        x = F.selu(x)\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "def test_conditional_mlp():\n",
    "    SHAPE = [2, 20]\n",
    "    T = 100\n",
    "    x = torch.ones(SHAPE)\n",
    "    t = torch.ones((2,)).long() * 5\n",
    "    model = ConditionalMLP(input_dim=20, num_embeds=100)\n",
    "    output = model(x, t)\n",
    "    assert list(output.shape) == SHAPE\n",
    "\n",
    "\n",
    "test_conditional_mlp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCXBSZe32F09"
   },
   "source": [
    "### DDPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEZ__C82KlzL"
   },
   "source": [
    "Let return to the ELBO. The main part of it is:\n",
    "$$\n",
    "    \\mathcal{L}_t = KL \\bigl(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) || p(\\mathbf{x}_{t - 1} | \\mathbf{x}_t, \\boldsymbol{\\theta} )\\bigr)\n",
    "$$\n",
    "\n",
    "In Lecture 11 we have got that\n",
    "$$\n",
    "    \\mathcal{L}_t = \\mathbb{E}_{\\boldsymbol{\\epsilon}} \\left[ \\frac{\\beta_t^2}{2 \\tilde{\\beta_t} \\alpha_t (1 - \\bar{\\alpha}_t)} \\| \\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t) \\|^2 \\right].\n",
    "$$\n",
    "\n",
    "In practice this loss is simplified. Particilarly, we will omit coefficient of the norm and we will sample index $t$ at each training step.\n",
    "\n",
    "Finally, we will train our model with the following objective:\n",
    "$$\n",
    "\\text{loss} = \\mathbb{E}_{\\mathbf{x}_0, \\boldsymbol{\\epsilon}, t}\\bigg[ \\|\\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t)\\|^2\\bigg],\n",
    "$$\n",
    "where $\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\boldsymbol{\\epsilon}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqPzHQ_32F09"
   },
   "source": [
    "The following class implements two methods:\n",
    "- `loss` - to compute the loss at the training step;\n",
    "- `sample` - to sample from the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTy1kSEy2F09"
   },
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    def __init__(self, num_timesteps: int, model: nn.Module):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        self.forward_diffusion = ForwardDiffusion(num_timesteps=num_timesteps)\n",
    "        self.reverse_diffusion = ReverseDiffusion(num_timesteps=num_timesteps)\n",
    "        self.model = model\n",
    "        self.shape = None\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "        \n",
    "\n",
    "    def sample(self, num_samples: int):\n",
    "        assert self.shape is not None\n",
    "        x = torch.randn((num_samples, *self.shape), device=self.device, dtype=torch.float32)\n",
    "        indices = list(range(self.num_timesteps))[::-1]\n",
    "\n",
    "        for i in tqdm(indices):\n",
    "            t = torch.tensor([i] * num_samples, device=x.device)\n",
    "            with torch.no_grad():\n",
    "                # ====\n",
    "                # your code\n",
    "                # 1) get epsilon from the model\n",
    "                # 2) sample from the reverse diffusion\n",
    "                eps = \n",
    "                x = \n",
    "                # ====\n",
    "        return x\n",
    "\n",
    "    def loss(self, x0):\n",
    "        if self.shape is None:\n",
    "            self.shape = list(x0.shape)[1:]\n",
    "        t = torch.randint(0, self.num_timesteps, size=(x0.size(0),), device=x0.device)\n",
    "        noise = torch.randn_like(x0)\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) get x_t\n",
    "        # 2) get epsilon from the model\n",
    "        # 3) compute mse loss between epsilon and noise\n",
    "        xt = \n",
    "        eps = \n",
    "\n",
    "        loss = \n",
    "        # ====\n",
    "        return {\"total_loss\": loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xw6vueDnTt7C"
   },
   "source": [
    "### Training\n",
    "\n",
    "Now we are ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100 # you could change it\n",
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "LR = \n",
    "EPOCHS = \n",
    "# ====\n",
    "\n",
    "model = ConditionalMLP(input_dim=2, num_embeds=T)\n",
    "ddpm = DDPM(num_timesteps=T, model=model)\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# try your own optimizer/scheduler\n",
    "optimizer = torch.optim.AdamW(ddpm.parameters(), lr=LR, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.995)\n",
    "\n",
    "dgm_utils.train_model(\n",
    "    model=ddpm,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE,\n",
    "    visualize_samples=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ijiAy6pUvkn"
   },
   "source": [
    "Now let's sample from our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ddpm.sample(num_samples=5000).cpu()\n",
    "\n",
    "dgm_utils.visualize_2d_samples(samples, title=\"Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RSpn0XJU_G9"
   },
   "source": [
    "Now let's see how denoising looks like (similarly to forward noising process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jXmq3s42F0-",
    "outputId": "56f3ee9e-b069-45ac-9690-4cda3fcf6716"
   },
   "outputs": [],
   "source": [
    "timestamps=[0, 2, 4, 10, 50]\n",
    "\n",
    "x = torch.randn(train_data.shape[0], 2, requires_grad=False).to(ddpm.device)\n",
    "for i in range(ddpm.num_timesteps - 1, -1, -1):\n",
    "    t = torch.tensor(i, dtype=torch.long, requires_grad=False).expand(x.shape[0]).to(ddpm.device)\n",
    "    with torch.no_grad():\n",
    "        eps = ddpm.model(x, t)\n",
    "        x = ddpm.reverse_diffusion.get_samples(xt=x, eps=eps, t=t)\n",
    "    if i in reversed(timestamps):\n",
    "        x_ = x.cpu()\n",
    "        dgm_utils.visualize_2d_samples(x_, title=f\"Samples from timestamp: {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXJnkzgiRGRo"
   },
   "source": [
    "## Task3: DDPM on MNIST (4pt)\n",
    "\n",
    "Let apply our diffusion model to the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oktOew8b2F1F",
    "outputId": "a6fc21c2-6862-4c8b-d163-11e41db863be"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = dgm_utils.load_dataset(\"mnist\", flatten=False, binarize=False)\n",
    "\n",
    "dgm_utils.visualize_images(train_data, \"MNIST samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFhOvS0PPZoe"
   },
   "source": [
    "Let's take a look at the forward process for the MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydfzM0RU2F1G",
    "outputId": "8317e111-ec29-4180-e7a5-c58207647a6e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = 1000\n",
    "\n",
    "fdiff = ForwardDiffusion(num_timesteps=T)\n",
    "\n",
    "timestamps=[0, 50, 100, 200, 300, 500, 600, 800, 999]\n",
    "\n",
    "plot_n_steps = len(timestamps)\n",
    "samples = []\n",
    "x0 = train_data[10:11]\n",
    "x0 = 2 * x0 - 1\n",
    "for i, t in enumerate(timestamps):\n",
    "    x = fdiff.get_samples(x0=torch.from_numpy(x0), t=torch.ones((x0.shape[0], 1)).long() * t)\n",
    "    samples.append(x.cpu().numpy())\n",
    "\n",
    "samples = np.concatenate(samples)\n",
    "samples = 0.5 * samples + 0.5\n",
    "dgm_utils.show_samples(samples, title=\"Noisy samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10tMXiU8P_6v"
   },
   "source": [
    "The model is written for you. We will use conditioned ResNet architecture. But you could change it if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNyTMSl42F1G"
   },
   "outputs": [],
   "source": [
    "class ConditionedResnetBlock(nn.Module):\n",
    "    def __init__(self, dim: int, num_embeddings: int) -> None:\n",
    "        super().__init__()\n",
    "        # you could experiment with this architecture\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(dim, dim, kernel_size=1),\n",
    "        )\n",
    "        self.dim = dim\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        time_embed = self.embedding(y).view(-1, self.dim, 1, 1)\n",
    "        return x + self.block(x + time_embed)\n",
    "\n",
    "\n",
    "class ConditionedSimpleResnet(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels: int, out_channels: int, n_filters: int, n_blocks: int, num_embeddings: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # you could experiment with this architecture\n",
    "        self.first_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, n_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layers = nn.Sequential(*[ConditionedResnetBlock(n_filters, num_embeddings) for _ in range(n_blocks)])\n",
    "        self.last_block = nn.Sequential(\n",
    "            nn.ReLU(), nn.Conv2d(n_filters, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.n_filters = n_filters\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.first_block(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, t)\n",
    "        x = self.last_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_conditioned_resnet():\n",
    "    model = ConditionedSimpleResnet(in_channels=1, out_channels=1, n_filters=16, n_blocks=1, num_embeddings=2)\n",
    "    x = torch.rand((1, 1, 28, 28))\n",
    "    t = torch.zeros(size=(1,), dtype=torch.long)\n",
    "    out1 = model(x, t)\n",
    "    t = torch.ones(size=(1,), dtype=torch.long)\n",
    "    out2 = model(x, t)\n",
    "    assert not np.allclose(out1.detach().numpy(), out2.detach().numpy())\n",
    "\n",
    "\n",
    "test_conditioned_resnet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we redefine two methods. Just to scale the data and clamp final samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMMNIST(DDPM):\n",
    "\n",
    "    def sample(self, num_samples: int):\n",
    "        x = super().sample(num_samples)\n",
    "        return torch.clamp(0.5 * x + 0.5, -1.0, 1.0)\n",
    "\n",
    "    def loss(self, x0):\n",
    "        x0 = 2.0 * x0 - 1.0\n",
    "        return super().loss(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V9Xv5wV2F1G"
   },
   "source": [
    "That is all. We are ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNvEMcANjpMk",
    "outputId": "f1234402-9298-4b2a-a445-13894a817ccb"
   },
   "outputs": [],
   "source": [
    "T = 1000\n",
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "LR = \n",
    "WEIGHT_DECAY = \n",
    "EPOCHS = \n",
    "N_FILTERS = \n",
    "N_BLOCKS = \n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model_mnist = ConditionedSimpleResnet(in_channels=1, out_channels=1, n_filters=N_FILTERS, n_blocks=N_BLOCKS, num_embeddings=T)\n",
    "ddpm_mnist = DDPMMNIST(num_timesteps=T, model=model_mnist)\n",
    "\n",
    "# try your own optimizer/scheduler\n",
    "optimizer = torch.optim.Adam(ddpm_mnist.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "dgm_utils.train_model(\n",
    "    model=ddpm_mnist,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4foGURhyRAaG"
   },
   "source": [
    "Let's draw samples from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10167,
     "status": "ok",
     "timestamp": 1699721305095,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "j89yASABkOve",
    "outputId": "3acb8522-1f90-46f1-e13c-02d1ef4ba68f"
   },
   "outputs": [],
   "source": [
    "ddpm_mnist = ddpm_mnist.to(DEVICE)\n",
    "\n",
    "samples = ddpm_mnist.sample(num_samples=25).cpu().numpy()\n",
    "\n",
    "dgm_utils.show_samples(samples, title=\"Samples\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
