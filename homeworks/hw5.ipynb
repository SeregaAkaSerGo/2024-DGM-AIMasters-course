{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZXJoDiD_x-N"
   },
   "source": [
    "# Homework5: Denoising score matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxF8ewFXn1HO"
   },
   "source": [
    "## Task 1: Theory (4pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sN6DycPP2Xq2"
   },
   "source": [
    "\n",
    "### Problem 1: Gaussian Diffusion (2pt)\n",
    "\n",
    "In the course we have discussed two types of gaussian diffusions:\n",
    "- $\\mathbf{x}_t = \\mathbf{x}_0 + \\sigma_t \\cdot \\boldsymbol{\\epsilon}$ - score-based models,\n",
    "- $\\mathbf{x}_t = \\sqrt{1 - \\beta_t} \\cdot \\mathbf{x}_{t-1} + \\sqrt{\\beta_t} \\cdot \\boldsymbol{\\epsilon}$ - diffusion models.\n",
    "\n",
    "One may ask, why we do not consider the more general diffusion models. It was the idea of the paper [Variational Diffusion Models](https://arxiv.org/abs/2107.00630).\n",
    "\n",
    "Let consider the diffusion of the form\n",
    "$$\n",
    "    \\mathbf{x}_t = \\alpha_t \\cdot \\mathbf{x}_0 + \\sigma_t \\cdot \\boldsymbol{\\epsilon}, \\quad \\mathbf{x}_t \\sim q(\\mathbf{x}_t | \\mathbf{x}_0) = \\mathcal{N}(\\alpha_t \\cdot \\mathbf{x}_0, \\sigma_t^2 \\cdot \\mathbf{I}).\n",
    "$$\n",
    "\n",
    "1) Show that if the variance of $\\mathbf{x}_t$ equals to the variance of $\\mathbf{x}_0$ then we came to the standard diffusion (in this case $\\alpha_t^2 = 1 - \\sigma_t^2$). That is why the standard diffusion is called **Variance Preserving**.\n",
    "\n",
    "2) Find the distribution $q(\\mathbf{x}_t | \\mathbf{x}_s)$ for $s < t$ (you have to derive the formulas for mean and variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbxPyzwcuinj"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n_qLVZe2Xq2"
   },
   "source": [
    "### Problem 2: Implicit score matching (2pt)\n",
    "\n",
    "We have discussed score matching task at Lecture 9. The objective of score matching is\n",
    "$$\n",
    "    \\frac{1}{2} \\mathbb{E}_{\\pi}\\bigl\\| \\mathbf{s}_{\\boldsymbol{\\theta}}(\\mathbf{x}) - \\nabla_\\mathbf{x} \\log \\pi(\\mathbf{x}) \\bigr\\|^2_2 \\rightarrow \\min_{\\boldsymbol{\\theta}}.\n",
    "$$\n",
    "\n",
    "And we have already known one possible solution for this task. It is denoising score matching.\n",
    "\n",
    "Here our goal is to derive one more way to solve the initial score matching problem. It is called **implicit score matching**.\n",
    "\n",
    "Let consider 1-d case ($x \\in \\mathbb{R}$).\n",
    "Prove that\n",
    "$$\n",
    "\\frac{1}{2} \\mathbb{E}_{\\pi}\\bigl\\| s_{\\boldsymbol{\\theta}}(x) - \\nabla_x \\log \\pi(x) \\bigr\\|^2_2 = \\mathbb{E}_{\\pi}\\left[ \\frac{1}{2}s^2_{\\boldsymbol{\\theta}}(x) + \\nabla_{x} s_{\\boldsymbol{\\theta}}(x) \\right] + \\text{const}.\n",
    "$$\n",
    "\n",
    "- **Q:** Why is the expression at the right hand side better than the left one? **A:** It is better because we do not have the term with the unknown distribution $\\pi(x)$.\n",
    "\n",
    "- **Q:** Why do we not use this expression instead of denoising score matching? **A:** In this expression we have term $\\nabla_{x} s_{\\boldsymbol{\\theta}}(x) = \\nabla^2_{x} \\log p(x | \\boldsymbol{\\theta})$. And it is difficult to work with the second derivates.\n",
    "\n",
    "- **Q:** Why do we consider only 1-d case? **A:** It is very straightforward to generalize this formula to the multidimensional case, but the derivation contains much more formulas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ApNxWRw2vPU"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jppIpVyZ2Xq3",
    "outputId": "629ad74a-6fad-434d-b7e5-e19ae589f687"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown\n",
    "\n",
    "COMMIT_HASH = \"2180d8447bc1c62bf662505d73f60d3e0d7ff03c\"\n",
    "!if [ -d dgm_utils ]; then rm -Rf dgm_utils; fi\n",
    "!git clone https://github.com/r-isachenko/dgm_utils.git\n",
    "%cd dgm_utils\n",
    "!git checkout {COMMIT_HASH}\n",
    "!pip install ./\n",
    "%cd ./..\n",
    "!rm -Rf dgm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Blg_otRk23ud"
   },
   "outputs": [],
   "source": [
    "import dgm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Snskjc-2_o4"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehGykW1bnNbo"
   },
   "source": [
    "## Task 2: Denoising score matching for 2D data (4 pts)\n",
    "\n",
    "In this task you will implement the denoising score matching model to the 2D moons dataset.\n",
    "\n",
    "Let's take a look at dataset samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2zCpepU3Bvw"
   },
   "outputs": [],
   "source": [
    "def generate_moons_data(count: int) -> tuple:\n",
    "    data, labels = make_moons(n_samples=count, noise=0.1)\n",
    "    data = data.astype(\"float32\")\n",
    "    split = int(0.8 * count)\n",
    "    train_data, test_data = data[:split], data[split:]\n",
    "    train_labels, test_labels = labels[:split], labels[split:]\n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "bJUHA3sy3Etb",
    "outputId": "a7fbcdd9-5a35-4850-b032-49017aa046fa"
   },
   "outputs": [],
   "source": [
    "COUNT = 5000\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = generate_moons_data(COUNT)\n",
    "dgm_utils.visualize_2d_data(train_data, test_data, train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07H5Put_nbTI"
   },
   "source": [
    "Let recall the theory of denoising score matching.\n",
    "\n",
    "The idea is the following. We define the score function\n",
    "$$\n",
    "    \\mathbf{s}_{\\boldsymbol{\\theta}}(\\mathbf{x}) = \\nabla_{\\mathbf{x}}\\log p(\\mathbf{x}| \\boldsymbol{\\theta}).\n",
    "$$\n",
    "\n",
    "Then we minimize the Fisher divergence to obtain the score function:\n",
    "$$\n",
    "    D_F(\\pi, p) = \\frac{1}{2}\\mathbb{E}_{\\pi}\\bigl\\| \\mathbf{s}_{\\boldsymbol{\\theta}}(\\mathbf{x}) - \\nabla_{\\mathbf{x}} \\log \\pi(\\mathbf{x}) \\bigr\\|^2_2 \\rightarrow \\min_{\\boldsymbol{\\theta}}\n",
    "$$.\n",
    "\n",
    "If we have the score function, we use the Langevin dynamics to sample from our model:\n",
    "$$\n",
    "    \\mathbf{x}_{l + 1} = \\mathbf{x}_l + \\frac{\\eta}{2} \\cdot \\nabla_{\\mathbf{x}_l} \\log p(\\mathbf{x}_l | \\boldsymbol{\\theta}) + \\sqrt{\\eta} \\cdot \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, \\mathbf{I}).\n",
    "$$\n",
    "\n",
    "But Fisher divergence is intractable and we use the noising procedure to get noised samples $\\mathbf{x}_{\\sigma} = \\mathbf{x} + \\sigma \\cdot \\boldsymbol{\\epsilon}$.\n",
    "\n",
    "Minimizing the Fisher divergence for the noisy samples is equivalent to the following objective:\n",
    "\\begin{multline*}\n",
    "    \\mathbb{E}_{q(\\mathbf{x}_{\\sigma})}\\bigl\\| \\mathbf{s}_{\\boldsymbol{\\theta}, \\sigma}(\\mathbf{x}_{\\sigma}) - \\nabla_{\\mathbf{x}_{\\sigma}} \\log q(\\mathbf{x}_{\\sigma}) \\bigr\\|^2_2 = \\\\\n",
    "    = \\mathbb{E}_{\\pi(\\mathbf{x})} \\mathbb{E}_{q(\\mathbf{x}_{\\sigma} | \\mathbf{x})}\\bigl\\| \\mathbf{s}_{\\boldsymbol{\\theta}, \\sigma}(\\mathbf{x}_{\\sigma}) - \\nabla_{\\mathbf{x}_{\\sigma}} \\log q(\\mathbf{x}_{\\sigma} | \\mathbf{x}) \\bigr\\|^2_2 + \\text{const}(\\boldsymbol{\\theta}).\n",
    "\\end{multline*}\n",
    "\n",
    "Here\n",
    "$$\n",
    "    \\log q(\\mathbf{x}_{\\sigma} | \\mathbf{x}) = - \\frac{\\mathbf{x}_{\\sigma} - \\mathbf{x}}{\\sigma^2} = - \\frac{\\boldsymbol{\\epsilon}}{\\sigma}.\n",
    "$$\n",
    "\n",
    "Therefore, the objective of the denoising score matching is\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{\\pi(\\mathbf{x})} \\mathbb{E}_{q(\\mathbf{x}_{\\sigma} | \\mathbf{x})}\\bigl\\| \\mathbf{s}_{\\boldsymbol{\\theta}, \\sigma}(\\mathbf{x}_{\\sigma}) + \\frac{\\boldsymbol{\\epsilon}}{\\sigma} \\bigr\\|^2_2 \\rightarrow \\min_{\\boldsymbol{\\theta}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ikuwxWM3Nba"
   },
   "outputs": [],
   "source": [
    "class DenoisingScoreMatcher(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            score_model: nn.Module,\n",
    "            input_shape: Tuple[int],\n",
    "            sigma: float\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.score_model = score_model\n",
    "        self.input_shape = input_shape\n",
    "        self.sigma = sigma\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # ====\n",
    "        # your code\n",
    "        # sample gaussian noise\n",
    "        # perturb samples using the noise and sigma\n",
    "        noisy_x = \n",
    "        # =====\n",
    "\n",
    "        # calculate the score model\n",
    "        s = self.score_model(noisy_x)\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # compute the loss\n",
    "        # it is mse between score function and gradient of the normal distribution\n",
    "        \n",
    "        # =====\n",
    "        return loss\n",
    "\n",
    "    def loss(self, x: torch.Tensor):\n",
    "        return {\"total_loss\": self(x).mean(dim=0).sum()}\n",
    "\n",
    "    def langevin_dynamics(self, x: torch.Tensor, num_steps: int, eta: float):\n",
    "        # =====\n",
    "        # your code\n",
    "        # apply Langevin dynamics in for-cycle to the starting point x\n",
    "        \n",
    "        # =====\n",
    "        return x\n",
    "\n",
    "    def sample(self, num_samples: int = 64, num_steps: int=100, eta: float = 0.01):\n",
    "        with torch.no_grad():\n",
    "            # we sample x_0 from U[-1, 1]\n",
    "            x0 = 2. * torch.rand_like(torch.empty(num_samples, *self.input_shape)) - 1.\n",
    "            x0 = x0.to(self.device)\n",
    "\n",
    "            # run langevine dynamics\n",
    "            x = self.langevin_dynamics(x0, num_steps=num_steps, eta=eta)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_denoiser_score_matcher():\n",
    "    matcher = DenoisingScoreMatcher(\n",
    "        score_model=nn.Linear(2, 2),\n",
    "        input_shape=(2,),\n",
    "        sigma=0.1\n",
    "    )\n",
    "    x = torch.rand(16, 2)\n",
    "    assert x.size() == matcher(x).size()\n",
    "    loss = matcher.loss(x)[\"total_loss\"]\n",
    "    assert len(loss.size()) == 0\n",
    "    assert list(matcher.sample(4).size()) == [4, 2]\n",
    "\n",
    "\n",
    "test_denoiser_score_matcher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaIv3M6crme-"
   },
   "source": [
    "That's all!\n",
    "\n",
    "And now we are ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "id": "ft98D6FT7FbY",
    "outputId": "36b02981-0d04-4590-bb2c-d243795ce879"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "\n",
    "BATCH_SIZE =   # any adequate value\n",
    "EPOCHS =   # > 50\n",
    "LR =   # > 1e-3\n",
    "HIDDEN_SIZE =   # > 32\n",
    "SIGMA =  # 0.01 < x < 1.0\n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# ====\n",
    "# your code\n",
    "# define sequential model\n",
    "# it is enough to use the sequence of Linear layers with activations\n",
    "score_model = \n",
    "# ====\n",
    "\n",
    "matcher = DenoisingScoreMatcher(\n",
    "    score_model=score_model, input_shape=(2,), sigma=SIGMA\n",
    ")\n",
    "\n",
    "# ====\n",
    "# your code\n",
    "# choose any optimizer/scheduler as you want\n",
    "optimizer = torch.optim.Adam(matcher.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "# ====\n",
    "\n",
    "dgm_utils.train_model(\n",
    "    matcher,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=DEVICE,\n",
    "    n_samples=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLUKPrror7GJ"
   },
   "source": [
    "Let sample from our model. Experiment with number of steps and $\\eta$ for Langevin dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "dQk73I-G_CVa",
    "outputId": "288009ca-fb1f-435a-d801-dace05be1269"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "NUM_STEPS = \n",
    "ETA = \n",
    "# ====\n",
    "\n",
    "samples = matcher.sample(num_samples=5000, num_steps=NUM_STEPS, eta=ETA).cpu()\n",
    "\n",
    "dgm_utils.visualize_2d_samples(samples, title=\"Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovZUhvWCsANm"
   },
   "source": [
    "## Task 3: Noise Conditioned Score Network for MNIST (5 pts)\n",
    "\n",
    "Now we try to extend our model to the NCSN. It means that we have to add multiple noise scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "id": "QZV79VwSEAXZ",
    "outputId": "9333ca5a-8e8f-465c-ca76-867bf86e6b3c"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = dgm_utils.load_dataset(\"mnist\", flatten=False, binarize=False)\n",
    "dgm_utils.visualize_images(train_data, \"MNIST samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izZsvHvIsJHU"
   },
   "source": [
    "Here we will use the resnet-like architecture. But we encourage you to experiment with it.\n",
    "\n",
    "The important thing here is the conditioning of the score model to noise. It means that the noise scale $\\sigma$ have to be the input of the model. We will use embedding layer to make this conditioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U99Orvw4H_4E"
   },
   "outputs": [],
   "source": [
    "class ConditionedResnetBlock(nn.Module):\n",
    "    def __init__(self, dim: int, num_embeddings: int) -> None:\n",
    "        super().__init__()\n",
    "        # you could experiment with this architecture\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(dim, dim, kernel_size=1),\n",
    "        )\n",
    "        self.dim = dim\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        # look carefully at this conditioning\n",
    "        time_embed = self.embedding(y).view(-1, self.dim, 1, 1)\n",
    "        return x + self.block(x + time_embed)\n",
    "\n",
    "\n",
    "class ConditionedSimpleResnet(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels: int, out_channels: int, n_filters: int, n_blocks: int, num_embeddings: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.first_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, n_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layers = nn.Sequential(*[ConditionedResnetBlock(n_filters, num_embeddings) for _ in range(n_blocks)])\n",
    "        self.last_block = nn.Sequential(\n",
    "            nn.ReLU(), nn.Conv2d(n_filters, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.n_filters = n_filters\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.first_block(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, y)\n",
    "        x = self.last_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_conditioned_resnet():\n",
    "    model = ConditionedSimpleResnet(in_channels=1, out_channels=1, n_filters=16, n_blocks=1, num_embeddings=2)\n",
    "    x = torch.rand((1, 1, 28, 28))\n",
    "    y = torch.zeros(size=(1,), dtype=torch.long)\n",
    "    out1 = model(x, y)\n",
    "    y = torch.ones(size=(1,), dtype=torch.long)\n",
    "    out2 = model(x, y)\n",
    "    assert not np.allclose(out1.detach().numpy(), out2.detach().numpy())\n",
    "\n",
    "\n",
    "test_conditioned_resnet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets define the main model.\n",
    "\n",
    "We will use the sequence of the noise levels: $\\sigma_1 < \\sigma_2 < \\dots < \\sigma_T$. In this task it will be the geometric progression.\n",
    "And we will perturb the original data with the different noise levels to obtain \n",
    "$$\n",
    "\\mathbf{x}_t = \\mathbf{x} + \\sigma_t \\cdot \\boldsymbol{\\epsilon}, \\quad \\mathbf{x}_t \\sim q(\\mathbf{x}_t). \n",
    "$$\n",
    "\n",
    "Our training objective:\n",
    "$$\n",
    "    \\sum_{t=1}^T \\frac{\\sigma_t^2}{\\sigma_T^2} \\mathbb{E}_{\\pi(\\mathbf{x})} \\mathbb{E}_{q(\\mathbf{x}_t | \\mathbf{x})}\\bigl\\| \\mathbf{s}_{\\boldsymbol{\\theta}, \\sigma_t}(\\mathbf{x}_t) - \\nabla_{\\mathbf{x}_{\\sigma}} \\log q(\\mathbf{x}_t | \\mathbf{x}) \\bigr\\|^2_2 \\rightarrow \\min_{\\boldsymbol{\\theta}}\n",
    "$$\n",
    "But instead of doing the honest summation we will sample one timestamp for each sample.\n",
    "\n",
    "We will use annealed Langevin dynamics to sample from our model:\n",
    "1. Sample $\\mathbf{x}_0 \\sim \\mathcal{N}(0, \\sigma_T^2 \\cdot \\mathbf{I}) \\approx q(\\mathbf{x}_T)$.\n",
    "2. Apply $L$ steps of Langevin dynamic\n",
    "$$\n",
    "    \\mathbf{x}_l = \\mathbf{x}_{l-1} + \\frac{\\eta_t}{2} \\cdot \\mathbf{s}_{\\boldsymbol{\\theta}, \\sigma_t}(\\mathbf{x}_{l - 1}) + \\sqrt{\\eta_t} \\cdot \\boldsymbol{\\epsilon}_l.\n",
    "$$\n",
    "3. Update $\\mathbf{x}_0 := \\mathbf{x}_L$ and choose the next $\\sigma_t$.\n",
    "4. Repeat it for all sigmas.\n",
    "\n",
    "**Note:** use the following formula for $\\eta_t = \\epsilon \\cdot \\frac{\\sigma_t^2}{\\sigma_T^2}$ ($\\epsilon$ is a small number that is a hyperparameter of the sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMSV8FqMV1h8"
   },
   "outputs": [],
   "source": [
    "class NoiseConditionedScoreNetwork(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            score_model: nn.Module,\n",
    "            input_shape: Tuple[int],\n",
    "            sigmas: List[float]\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.score_model = score_model\n",
    "        self.input_shape = input_shape\n",
    "        self.sigmas = torch.FloatTensor(sorted(sigmas, reverse=True))\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        self.sigmas = self.sigmas.to(self.device)\n",
    "        batch_size = x.shape[0]\n",
    "        # ====\n",
    "        # your code\n",
    "        # sample gaussian noise\n",
    "        # sample timestamps for each datapoint in the batch\n",
    "        # choose sigmas for these datapoints\n",
    "        # add noises to the x samples\n",
    "        noisy_x = \n",
    "        # =====\n",
    "\n",
    "        # calculate the score model\n",
    "        s = self.score_model(noisy_x, which_sigmas)\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # compute the loss\n",
    "        # it is mse between score function and gradient of the normal distribution (do not forget the coefficient before the mse)\n",
    "        \n",
    "        # =====\n",
    "        return loss\n",
    "\n",
    "    def loss(self, x: torch.Tensor):\n",
    "        return {\"total_loss\": self(x).mean(dim=0).sum()}\n",
    "\n",
    "    def annealed_langevin_dynamics(self, x: torch.Tensor, num_steps: int, eps: float):\n",
    "        # =====\n",
    "        # your code\n",
    "        # here we will have 2 cycles: one for sigmas, one for Langevin sampling\n",
    "        # start with the largest sigma, apply Langevin dynamic for it and move to the next sigma\n",
    "        \n",
    "        # =====\n",
    "        return x\n",
    "\n",
    "    def sample(self, num_samples: int = 64, num_steps: int=100, eps: float = 0.1):\n",
    "        with torch.no_grad():\n",
    "            # we sample x_0 from U[-1, 1]\n",
    "            x0 = 2. * torch.rand_like(torch.empty(num_samples, *self.input_shape)) - 1.\n",
    "            x0 = x0.to(self.device)\n",
    "\n",
    "            # run langevine dynamics\n",
    "            x = self.annealed_langevin_dynamics(x0, num_steps=num_steps, eps=eps)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_ncsn():\n",
    "    class DummyConditionedMLP(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.layer = nn.Linear(2, 2)\n",
    "\n",
    "        def forward(self, x: torch.Tensor, y: torch.Tensor):\n",
    "            y = y.view(-1, 1)\n",
    "            return self.layer(x) + y\n",
    "\n",
    "\n",
    "    ncsn = NoiseConditionedScoreNetwork(\n",
    "        score_model=DummyConditionedMLP(),\n",
    "        input_shape=(2,),\n",
    "        sigmas=[0.1]\n",
    "    )\n",
    "    x = torch.rand(16, 2)\n",
    "    assert x.size() == ncsn(x).size()\n",
    "    loss = ncsn.loss(x)[\"total_loss\"]\n",
    "    assert len(loss.size()) == 0\n",
    "    assert list(ncsn.sample(4).size()) == [4, 2]\n",
    "\n",
    "\n",
    "test_ncsn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 10\n",
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "SIGMA_MIN = \n",
    "SIGMA_MAX = \n",
    "# ====\n",
    "q = (SIGMA_MAX / SIGMA_MIN) ** (1 / (L - 1))\n",
    "SIGMAS = [SIGMA_MIN * q**i for i in range(0, L)]\n",
    "print(SIGMAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "OlQLodUHGoYq",
    "outputId": "01005210-060a-49f6-dc8e-c5275f02cfc3"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE =   # any adequate value\n",
    "LR =   # <= 1e-3\n",
    "EPOCHS =   # <= 30\n",
    "N_FILTERS =   # < 128\n",
    "N_BLOCKS =   # < 8\n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(2 * train_data - 1, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(2 * test_data - 1, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "score_model = ConditionedSimpleResnet(\n",
    "     in_channels=1, out_channels=1, n_filters=N_FILTERS, n_blocks=N_BLOCKS, num_embeddings=len(SIGMAS)\n",
    ")\n",
    "\n",
    "ncsn = NoiseConditionedScoreNetwork(\n",
    "    score_model=score_model, input_shape=(1, 28, 28), sigmas=SIGMAS,\n",
    ")\n",
    "\n",
    "# ====\n",
    "# your code\n",
    "# choose any optimizer/scheduler as you want\n",
    "optimizer = torch.optim.Adam(ncsn.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "# ====\n",
    "\n",
    "# train\n",
    "dgm_utils.train_model(\n",
    "    ncsn,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "wjZS5HMpMb5t",
    "outputId": "b48864a8-985e-44dc-ab3b-6d23c2139dfd"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "NUM_STEPS = \n",
    "EPS = \n",
    "# ====\n",
    "\n",
    "samples = ncsn.sample(100, num_steps=NUM_STEPS, eps=EPS).cpu()\n",
    "samples = torch.clamp(0.5 * samples + 0.5, 0.0, 1.0)\n",
    "dgm_utils.show_samples(samples, \"MNIST samples\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1419c6699da14696a4dfcfa27645cbca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e2b4a42fa06484685e6dbbb718dd906",
      "placeholder": "​",
      "style": "IPY_MODEL_4bcd480b39ed49ef9fe7b619dac807b8",
      "value": " 10/10 [06:45&lt;00:00, 40.63s/it]"
     }
    },
    "24023cb9b33a47d79482e22c0d78c59f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "344606256fe7408981e4b7c28f17f3ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42e391bd46eb45f08aec7176554e039a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4bcd480b39ed49ef9fe7b619dac807b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "520e625662814b2f99edc701c9903cd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6abe89cddbba4ad0a838389391559646": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24023cb9b33a47d79482e22c0d78c59f",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_42e391bd46eb45f08aec7176554e039a",
      "value": 10
     }
    },
    "8e2b4a42fa06484685e6dbbb718dd906": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b19b8e868107423d8af000da1d7a0883": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed0a4216cd004a9c9ab730676c43d3f2",
       "IPY_MODEL_6abe89cddbba4ad0a838389391559646",
       "IPY_MODEL_1419c6699da14696a4dfcfa27645cbca"
      ],
      "layout": "IPY_MODEL_ee741df5e91a40bba1e091ab4ddae28f"
     }
    },
    "ed0a4216cd004a9c9ab730676c43d3f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_344606256fe7408981e4b7c28f17f3ca",
      "placeholder": "​",
      "style": "IPY_MODEL_520e625662814b2f99edc701c9903cd9",
      "value": "100%"
     }
    },
    "ee741df5e91a40bba1e091ab4ddae28f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
