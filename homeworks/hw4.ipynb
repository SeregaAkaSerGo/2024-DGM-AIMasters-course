{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRCQvjhe9FYV"
   },
   "source": [
    "# Homework4: Wasserstein GANs and GAN evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ptW8_Cp-0W6"
   },
   "source": [
    "## Task 1: Theory (4pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-b1xWc1Z_ni"
   },
   "source": [
    "### Problem 1: Least Squares GAN (1pt)\n",
    "    \n",
    "The Vanilla GAN often suffers from problems with a vanishing gradient. [Least Squares GAN](https://arxiv.org/abs/1611.04076) tries to solve this problem by replacing the error function with the following:\n",
    "$$\n",
    "   \t\\min_D V(D) = \\min_D \\frac{1}{2}\\left[ \\mathbb{E}_{\\pi(\\mathbf{x})} (D(\\mathbf{x}) - b)^2 + \\mathbb{E}_{p(\\mathbf{z})} (D(G(\\mathbf{z})) - a)^2 \\right]\n",
    "$$\n",
    "$$\n",
    "   \t\\min_G V(G) = \\min_G \\frac{1}{2}\\left[ \\mathbb{E}_{\\pi(\\mathbf{x})} (D(\\mathbf{x}) - c)^2 + \\mathbb{E}_{p(\\mathbf{z})} (D(G(\\mathbf{z})) - c)^2 \\right],\n",
    "$$\n",
    "where $a,b,c \\in \\mathbb{R}$ some fixed constants.\n",
    "\n",
    "1) Write out the formula for the optimal discriminator $D^*$.\n",
    "  \n",
    "2) Write out the expression for the error function of the generator $V(G)$ in the case of an optimal discriminator $D^*$.\n",
    "  \n",
    "3) Prove that for $b - c = 1$, $b - a = 2$, the error function of the generator $V(G)$ in the case of the optimal discriminator $D^*$ takes the form:\n",
    "$$\n",
    "   \tV(G) = \\chi^2_{\\text{Pearson}} \\left(\\frac{\\pi(\\mathbf{x}) + p(\\mathbf{x} | \\boldsymbol{\\theta})}{2} || p(\\mathbf{x} | \\boldsymbol{\\theta})\\right),\n",
    "$$\n",
    "where $\\chi^2_{\\text{Pearson}} (p || q)$ is a squared Pearson divergence:\n",
    "$$\n",
    "   \t\\chi^2_{\\text{Pearson}} (p || q) = \\int \\frac{(p(\\mathbf{x}) - q(\\mathbf{x}))^2}{p(\\mathbf{x})} d \\mathbf{x}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_S_4rXazaCKS"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbg3n5qXZRWW"
   },
   "source": [
    "### Problem 2: Conjugate functions / f-GAN (1pt)\n",
    "\n",
    "We have discussed the framework for f-divergence minimization at the Lecture 8. There we have got the variational inequality for f-divergence using Fenchel conjugate function:\n",
    "$$\n",
    "    D_f(\\pi || p) \\geq \\sup_{T \\in \\mathcal{T}} \\left[\\mathbb{E}_{\\pi}T(\\mathbf{x}) -  \\mathbb{E}_p f^*(T(\\mathbf{x})) \\right].\n",
    "$$\n",
    "Here\n",
    "$$\n",
    "\tf^*(t) = \\sup_{u \\in \\text{dom}_f} \\left( ut - f(u) \\right), \\quad f(u) = \\sup_{t \\in \\text{dom}_{f^*}} \\left( ut - f^*(t) \\right).\n",
    "$$\n",
    "\n",
    "In this task you have to derive standard GAN objective from the variational inequality.\n",
    "\n",
    "Let define function $f(u) = u \\log u - (u + 1) \\log (u + 1)$.\n",
    "\n",
    "- Find $\\text{dom}(f)$.\n",
    "- Show that $f^*(t) = - \\log (1 - e^t)$.\n",
    "- Use reparametrization $T(\\mathbf{x}) = \\log D(\\mathbf{x})$ to get the standard GAN objective (note that $D(\\mathbf{x}) \\in (0, 1)$, explain why this reparametrization is correct).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UIfd2ibZz-3"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TC5tQ0odEmgM"
   },
   "source": [
    "### Problem 3: Frechet Inception Distance  (2pt)\n",
    "Let prove the theorem from the Lecture 8.\n",
    "Remember the Wasserstein metric:\n",
    "$$\n",
    "    W_s(\\pi, p) = \\inf_{\\gamma \\in \\Gamma(\\pi, p)} \\left(\\mathbb{E}_{(\\mathbf{x}, \\mathbf{y}) \\sim \\gamma} \\| \\mathbf{x} - \\mathbf{y} \\|^s\\right)^{1/s}\n",
    "$$\n",
    "\n",
    "Consider the case $\\mathbf{x} \\sim \\pi(\\mathbf{x}) = \\mathcal{N}(\\boldsymbol{\\mu}_1, \\sigma_1^2 \\mathbf{I})$, $\\mathbf{y} \\sim p(\\mathbf{y}) = \\mathcal{N}(\\boldsymbol{\\mu}_2, \\sigma_2^2 \\mathbf{I})$.\n",
    "\n",
    "Let prove that in this case\n",
    "$$\n",
    "    W_2^2(\\pi, p) = \\inf_{\\gamma \\in \\Gamma(\\pi, p)} \\mathbb{E}_{(\\mathbf{x}, \\mathbf{y}) \\sim \\gamma} \\| \\mathbf{x} - \\mathbf{y} \\|^2 = \\| \\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2 \\|^2 + m \\cdot (\\sigma_1 - \\sigma_2)^2.\n",
    "$$\n",
    "Here $m$ is a dimensionality of the space ($\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^m$).\n",
    "\n",
    "**Hints:** (one of the possible solutions)\n",
    "1. Consider the case $\\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2 = 0$.\n",
    "2. Use Cauchyâ€“Schwarz inequality to prove that the value given above is a minimal.\n",
    "2. Find the analytical mapping between $\\mathbf{x}$ and $\\mathbf{y}$ that gives this value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-IpxlITHiF_"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJQYtKgA5ate",
    "outputId": "90a4a0b8-e86b-4edf-fbbf-7a329cb90dc6"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown\n",
    "\n",
    "REPO_NAME = \"2024-DGM-AIMasters-course\"\n",
    "!if [ -d {REPO_NAME} ]; then rm -Rf {REPO_NAME}; fi\n",
    "!git clone https://github.com/r-isachenko/{REPO_NAME}.git\n",
    "!cd {REPO_NAME}\n",
    "!pip install ./{REPO_NAME}/homeworks/\n",
    "!mv ./{REPO_NAME}/homeworks/stylegan.py ./stylegan.py\n",
    "!mv ./{REPO_NAME}/homeworks/inception.py ./inception.py\n",
    "!rm -Rf {REPO_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXhgRngvaed4"
   },
   "outputs": [],
   "source": [
    "from dgm_utils import train_model, show_samples, plot_training_curves\n",
    "from dgm_utils import visualize_images, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVBow6mXafwx",
    "outputId": "1c2e39dd-3fe8-410a-f0cc-e10360260224"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Optional\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.nn import functional as F\n",
    "from inception import InceptionV3\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "\n",
    "def reset_seed():\n",
    "    OUTPUT_SEED = 0xBADBEEF\n",
    "    torch.manual_seed(OUTPUT_SEED)\n",
    "    np.random.seed(OUTPUT_SEED)\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "print(\"cuda is available:\", USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sl59dviN5ekr"
   },
   "outputs": [],
   "source": [
    "from dgm_utils import show_samples, plot_training_curves\n",
    "from dgm_utils import visualize_images, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftMgDK_cPFmD"
   },
   "outputs": [],
   "source": [
    "# do not change this function\n",
    "def plot_losses(losses: np.ndarray, title: str):\n",
    "    n_itr = len(losses)\n",
    "    xs = np.arange(n_itr)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(xs, losses)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(\"Iterations\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8klUHHmAjHsI"
   },
   "source": [
    "## Task 2: Wasserstein GANs for CIFAR 10 (5pt)\n",
    "\n",
    "In this task you will fit different kinds of Wasserstein GANs (different ways to enforce Lipschitzness) that we discussed at the Lecture 8 to the CIFAR10 dataset\n",
    "* [WGAN](https://arxiv.org/abs/1701.07875) - standard Wasserstein GAN with weight clipping;\n",
    "* [WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf) - Wasserstein GAN with Gradient Penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "dAvSLXlKZ5q7",
    "outputId": "7b7c65bd-d4fa-437b-e99e-f5a7ae35dfd8"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = load_dataset(\"cifar10\", flatten=False, binarize=False)\n",
    "visualize_images(train_data, \"CIFAR10 samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PnfAHgw32Hr"
   },
   "source": [
    "### Problem 1: WGAN (3pt)\n",
    "\n",
    "[WGAN](https://arxiv.org/abs/1701.07875) model uses weight clipping to enforce Lipschitzness of the critic.\n",
    "\n",
    "The model objective is\n",
    "$$\n",
    "\\min_{G} W(\\pi || p) \\approx \\min_{G} \\max_{\\boldsymbol{\\phi} \\in \\boldsymbol{\\Phi}} \\left[ \\mathbb{E}_{\\pi(\\mathbf{x})} f_{\\boldsymbol{\\phi}}(\\mathbf{x})  - \\mathbb{E}_{p(\\mathbf{z})} f_{\\boldsymbol{\\phi}}(G_{\\boldsymbol{\\theta}}(\\mathbf{z}))\\right].\n",
    "$$\n",
    "Here $f_{\\boldsymbol{\\phi}}(\\mathbf{x})$ is the critic model. The critic weights $\\boldsymbol{\\phi}$ should lie in the compact set $\\boldsymbol{\\Phi} = [-c, c]^d$.\n",
    "\n",
    "In this task we will use convolutional networks for the generator $G_{\\boldsymbol{\\theta}}(\\mathbf{z})$ and the critic $f_{\\boldsymbol{\\phi}}(\\mathbf{x})$.\n",
    "\n",
    "First of all, let define generator network. It will be the same for all WGAN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a7fjcx0vL8R"
   },
   "outputs": [],
   "source": [
    "class ConvGenerator(nn.Module):\n",
    "    def __init__(self, input_size: int = 128, n_channels: int = 64) -> None:\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.input_size = input_size\n",
    "        # ====\n",
    "        # your code\n",
    "        # ====\n",
    "        \n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # apply all layers\n",
    "        \n",
    "        # ====\n",
    "        return output.view(-1, 3, 32, 32)\n",
    "\n",
    "    def sample(self, n_samples: int) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # sample from standard normal distribution and apply the model\n",
    "        \n",
    "        # ====\n",
    "        return output\n",
    "        \n",
    "        \n",
    "def test_conv_generator():\n",
    "    model = ConvGenerator(input_size=4, n_channels=32)\n",
    "    x = torch.randn((2, 4))\n",
    "    out = model(x)\n",
    "    assert list(out.size()) == [2, 3, 32, 32], out.size()\n",
    "    \n",
    "    out = model.sample(10)\n",
    "    assert list(out.size()) == [10, 3, 32, 32], out.size()\n",
    "\n",
    "    \n",
    "test_conv_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uVbwHvAruFh"
   },
   "source": [
    "Now it is time to define our critic. Here we will use the same class for all WGAN models, but the arguments will depend on the WGAN mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFA0tI7ZrloP"
   },
   "outputs": [],
   "source": [
    "class ConvCritic(nn.Module):\n",
    "    def __init__(\n",
    "        self, n_channels: int, clip_c: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.clip_c = clip_c\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "\n",
    "        # ====\n",
    "\n",
    "    def clip_weights(self) -> None:\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, nn.Linear) or isinstance(layer, nn.Conv2d):\n",
    "                # ====\n",
    "                # your code\n",
    "                # clip the weight to the range [-clip_c, clip_c]\n",
    "                \n",
    "                # ====\n",
    "                layer.weight.data = weight\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) clip the critic weights (if clip_c is given)\n",
    "        # 2) apply all layers\n",
    "        \n",
    "        # ====\n",
    "        return output\n",
    "        \n",
    "        \n",
    "def test_conv_critic():\n",
    "    model = ConvCritic(n_channels=4, clip_c=0.01)\n",
    "    x = torch.randn((2, 3, 32, 32))\n",
    "    out = model(x)\n",
    "    assert list(out.size()) == [2, 1], out.size()\n",
    "\n",
    "    \n",
    "test_conv_critic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDi02jfKAVN-"
   },
   "outputs": [],
   "source": [
    "def train_wgan(\n",
    "    generator: nn.Module,\n",
    "    critic: nn.Module,\n",
    "    train_loader: object,\n",
    "    critic_steps: int,\n",
    "    batch_size: int,\n",
    "    n_epochs: int,\n",
    "    lr: float,\n",
    "    use_cuda: bool = False,\n",
    "    gp_weight: Optional[float] = None,\n",
    ") -> dict:\n",
    "\n",
    "    if use_cuda:\n",
    "        critic = critic.cuda()\n",
    "        generator = generator.cuda()\n",
    "    critic.train()\n",
    "    generator.train()\n",
    "\n",
    "    gen_optimizer = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0, 0.9))\n",
    "    critic_optimizer = torch.optim.Adam(critic.parameters(), lr=lr, betas=(0, 0.9))\n",
    "\n",
    "    curr_iter = 0\n",
    "    d_loss, g_loss = torch.zeros(1), torch.zeros(1)\n",
    "    batch_loss_history = {\"discriminator_losses\": [], \"generator_losses\": []}\n",
    "    for epoch_i in tqdm(range(n_epochs)):\n",
    "        critic.train()\n",
    "        generator.train()\n",
    "        for batch_i, x in enumerate(train_loader):\n",
    "            curr_iter += 1\n",
    "            if use_cuda:\n",
    "                x = x.cuda()\n",
    "\n",
    "            # do a critic update\n",
    "            critic_optimizer.zero_grad()\n",
    "            fake_data = generator.sample(x.shape[0])\n",
    "\n",
    "            # ====\n",
    "            # your code\n",
    "            # D(x_fake) - D(x_real)\n",
    "            \n",
    "            # ====\n",
    "\n",
    "            if gp_weight is not None:\n",
    "                gp = gradient_penalty(critic, x, fake_data)\n",
    "                d_loss += gp_weight * gp\n",
    "\n",
    "            d_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "\n",
    "            # generator update\n",
    "            if curr_iter % critic_steps == 0:\n",
    "                gen_optimizer.zero_grad()\n",
    "                fake_data = generator.sample(batch_size)\n",
    "                # ====\n",
    "                # your code\n",
    "                # -D(x_fake)\n",
    "                \n",
    "                # ====\n",
    "                g_loss.backward()\n",
    "                gen_optimizer.step()\n",
    "\n",
    "                batch_loss_history[\"generator_losses\"].append(g_loss.data.cpu().numpy())\n",
    "                batch_loss_history[\"discriminator_losses\"].append(\n",
    "                    d_loss.data.cpu().numpy()\n",
    "                )\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        generator.eval()\n",
    "        critic.eval()\n",
    "        with torch.no_grad():\n",
    "            samples = generator.sample(100)\n",
    "            samples = samples.cpu().detach().numpy()\n",
    "\n",
    "        show_samples(samples, title=f\"Generated samples: epoch: {epoch_i}\")\n",
    "\n",
    "    return batch_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2d52084a512f4055ad01a9afbfaffff5",
      "1f880ad04f534e08aad0a006a33ed646",
      "25a3dc242d10469abc5a211dbc0746ca",
      "a9b2b099d36149dda1a92bb1eece775b",
      "d3b97e8914794f98bf81d84a2aadfe52",
      "8fca1a010dc84a2aadfc6b4e5f15d1f6",
      "d013d0fa6ee74b4ead7dc4f66d55f77c",
      "fb1bf34d7e344a5f9f459c0905548652",
      "144b17bde62042ac86f4c3507240ac1e",
      "abc7b4bf2975473e8de753c032e6e212",
      "7d18d94ae32941f7adfab36d7b49f61e"
     ]
    },
    "id": "bjOGNNU59Fr_",
    "outputId": "693ddaeb-0172-4dbd-e559-2757ecd5dc53"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE =   # any adequate value\n",
    "N_CHANNELS =   # > 32\n",
    "N_EPOCHS =   # > 10\n",
    "CRITIC_STEPS =   # > 2\n",
    "CLIP_C =   # < 1\n",
    "LR =   # < 1e-3\n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = ConvGenerator(n_channels=N_CHANNELS)\n",
    "critic = ConvCritic(n_channels=N_CHANNELS, clip_c=CLIP_C)\n",
    "\n",
    "train_losses = train_wgan(\n",
    "    generator,\n",
    "    critic,\n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    use_cuda=USE_CUDA,\n",
    ")\n",
    "\n",
    "plot_losses(train_losses[\"discriminator_losses\"], \"Discriminator loss\")\n",
    "plot_losses(train_losses[\"generator_losses\"], \"Generator loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2oddhso98hq"
   },
   "source": [
    "Let sample from our model and draw the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "EXWKEKxQ9_DH",
    "outputId": "cc8bff11-01f1-40f4-dd9b-470b1f3a1b94"
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "critic.eval()\n",
    "with torch.no_grad():\n",
    "    samples = generator.sample(100)\n",
    "    samples = samples.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "show_samples(samples, title=\"CIFAR-10 WGAN-generated samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZG4ErQLNjZr9"
   },
   "source": [
    "### Problem 2: WGAN-GP for CIFAR 10 (2pt)\n",
    "\n",
    "[WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf)  model uses gradient penalty to enforce Lipschitzness.\n",
    "\n",
    "The model objective is\n",
    "$$\n",
    "    W(\\pi || p) = \\underbrace{\\mathbb{E}_{\\pi(\\mathbf{x})} f(\\mathbf{x})  - \\mathbb{E}_{p(\\mathbf{x} | \\boldsymbol{\\theta})} f(\\mathbf{x})}_{\\text{original critic loss}} + \\lambda \\underbrace{\\mathbb{E}_{U[0, 1]} \\left[ \\left( \\| \\nabla_{\\hat{\\mathbf{x}}} f(\\hat{\\mathbf{x}}) \\|_2 - 1 \\right) ^ 2\\right]}_{\\text{gradient penalty}},\n",
    "$$\n",
    "where the samples $\\hat{\\mathbf{x}}_t = t \\mathbf{x} + (1 - t) \\mathbf{y}$ with $t \\in [0, 1]$ are uniformly sampled along straight lines between pairs of points: $\\mathbf{x}$ from the data distribution $\\pi(\\mathbf{x})$ and $\\mathbf{y}$ from the generator distribution $p(\\mathbf{x} | \\boldsymbol{\\theta}))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aTCJKgoAuUm"
   },
   "source": [
    "Let define our gradient penalty loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RXJ6autArvg"
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(\n",
    "    critic: object, real_data: torch.Tensor, fake_data: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    batch_size = real_data.shape[0]\n",
    "\n",
    "    # ====\n",
    "    # your code\n",
    "    # Calculate interpolation x_t = t * x_real + (1 - t) x_fake\n",
    "    # 1) sample t\n",
    "    # 2) create x_t (be careful about shapes)\n",
    "    # 3) apply critic to x_t\n",
    "\n",
    "    x_t = \n",
    "    d_output = \n",
    "    # ====\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_output,\n",
    "        inputs=x_t,\n",
    "        grad_outputs=torch.ones(d_output.size()).to(fake_data.device),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.reshape(batch_size, -1)\n",
    "    # ====\n",
    "    # your code\n",
    "    # compute gradient norm\n",
    "    gradients_norm = \n",
    "    # ====\n",
    "    return ((gradients_norm - 1) ** 2).mean()\n",
    "\n",
    "\n",
    "def test_gradient_penalty():\n",
    "    x = np.random.normal(size=(10, 4))\n",
    "    x_norm = np.mean(np.sqrt(x**2))\n",
    "    x = torch.randn(size=(10, 4))\n",
    "    x.requires_grad = True\n",
    "    assert gradient_penalty(lambda x: x, x, x).numpy() == 1\n",
    "    assert gradient_penalty(lambda x: x * 0, x, x).numpy() == 1\n",
    "\n",
    "\n",
    "test_gradient_penalty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBRZJXGAryNA"
   },
   "source": [
    "That is all :)\n",
    "\n",
    "We will use the same `ConvGenerator`, `ConvCritic` and `train_wgan()` as for WGAN model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432,
     "referenced_widgets": [
      "7d0563bf68604b8b9614d4fe0a8f992b",
      "950787f7d6934287a86a0a38c57ae29d",
      "89eb7c59a8e84fefa0db7f440f6848bb",
      "8afb4f28944145c3b90bacb6cb3b6327",
      "77b9f77796ab4344a23847d02e2087e0",
      "f29ce587aa53499c9c9e9c589be8f320",
      "518e7454eaa14f10ada3781a2401b622",
      "0057c56e43504274858faf340424348c",
      "639c32ab53164d7f9df57757b6e5c9c2",
      "a25e239d5cfd4c04a0569ee909df63e5",
      "bf5f3024f475431ca24c96f147255d75"
     ]
    },
    "id": "aY6qzJ5MSuiX",
    "outputId": "15b8c85e-24eb-4db3-8282-6736bcab5ddb"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE =   # any adequate value\n",
    "N_CHANNELS =   # > 32\n",
    "N_EPOCHS =   # > 10\n",
    "CRITIC_STEPS =   # > 2\n",
    "GP_WEIGHT =   # > 5\n",
    "LR = 1  # < 1e-3\n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = ConvGenerator(n_channels=N_CHANNELS)\n",
    "critic = ConvCritic(n_channels=N_CHANNELS)\n",
    "\n",
    "train_losses = train_wgan(\n",
    "    generator,\n",
    "    critic,\n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    gp_weight=GP_WEIGHT,\n",
    "    use_cuda=USE_CUDA,\n",
    ")\n",
    "\n",
    "plot_losses(train_losses[\"discriminator_losses\"], \"Discriminator loss\")\n",
    "plot_losses(train_losses[\"generator_losses\"], \"Generator loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unAqs_pEs59l"
   },
   "source": [
    "Let sample from our model and draw the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8I0pNzHchqRs"
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "critic.eval()\n",
    "with torch.no_grad():\n",
    "    samples = generator.sample(100)\n",
    "    samples = samples.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "show_samples(samples, title=\"CIFAR-10 WGAN-GP-generated samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1VlsYZxahzg"
   },
   "source": [
    "## Task 3: Inception Score and FID (4pt)\n",
    "\n",
    "Here our goal is to understand how to evaluate likelihood-free models using [Inception Score](https://arxiv.org/pdf/1606.03498.pdf) and [Frechet Inception Distance](https://arxiv.org/pdf/1706.08500.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mhhPc1kai3i"
   },
   "outputs": [],
   "source": [
    "# this is a helper function that we will use further\n",
    "def resize_tensor(x: torch.Tensor, image_size: int) -> torch.Tensor:\n",
    "    return F.interpolate(\n",
    "        x, size=(image_size, image_size), mode=\"bilinear\", align_corners=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwJA54t1anB5"
   },
   "source": [
    "Your task is to implement the *Inception score* and *FID* score and estimate the quality of two trained *StyleGAN* models we have discussed on Seminar 9 and Seminar 10:\n",
    "\n",
    "1. `stylegan_wgangp` is a *StyleGAN* model trained with *WGAN-GP* loss on CIFAR10 dataset ([ckpt_link](https://drive.google.com/file/d/1bTDbmleLXowuGcahsoSBeihSVbGgW52X/view?usp=sharing))\n",
    "\n",
    "2. `stylegan_r1` is a *StyleGAN* model trained with standard gan loss with $R_1$ regularization on CIFAR10 dataset ([ckpt_link](https://drive.google.com/file/d/1PNeESbetxazQkBJbBnoizyWgGKJwfpW5/view?usp=sharing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92lCY5Y0aoOk"
   },
   "outputs": [],
   "source": [
    "# loading models checkpoints\n",
    "!gdown --id 1bTDbmleLXowuGcahsoSBeihSVbGgW52X\n",
    "!gdown --id 1PNeESbetxazQkBJbBnoizyWgGKJwfpW5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVdby-Hkap-J"
   },
   "outputs": [],
   "source": [
    "from stylegan import MicroStyleGANGenerator\n",
    "from copy import deepcopy\n",
    "\n",
    "sg_wgangp_name = \"stylegan_wgangp_loss_FINAL.pth\"\n",
    "sg_gan_r1_name = \"stylegan_gan_r1_loss_FINAL.pth\"\n",
    "\n",
    "\n",
    "stylegan_wgangp = MicroStyleGANGenerator(\n",
    "    z_dim=128,\n",
    "    map_hidden_dim=256,\n",
    "    w_dim=64,\n",
    "    in_chan=64,\n",
    "    out_chan=3,\n",
    "    kernel_size=3,\n",
    "    hidden_chan=32,\n",
    ")\n",
    "\n",
    "stylegan_r1 = deepcopy(stylegan_wgangp)\n",
    "\n",
    "stylegan_wgangp.load_state_dict(\n",
    "    torch.load(\"./{}\".format(sg_wgangp_name), map_location=\"cpu\")[\"generator\"]\n",
    ")\n",
    "\n",
    "stylegan_r1.load_state_dict(\n",
    "    torch.load(\"./{}\".format(sg_gan_r1_name), map_location=\"cpu\")[\"generator\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phZS-ESMar61"
   },
   "source": [
    "Let's look at model samples from `stylegan_r1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOS0EkE3asNK"
   },
   "outputs": [],
   "source": [
    "batch = stylegan_r1.sample(100).detach().cpu().numpy()\n",
    "show_samples(batch, \"CIFAR10 samples, shape = ({0}, {0})\".format(32), nrow=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11l8BP97avOn"
   },
   "source": [
    "Let's look at model samples from `stylegan_wgangp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZB6-Jgfavq8"
   },
   "outputs": [],
   "source": [
    "batch = stylegan_wgangp.sample(100).detach().cpu().numpy()\n",
    "show_samples(batch, \"CIFAR10 samples, shape = ({0}, {0})\".format(32), nrow=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FT34n2CYayMR"
   },
   "source": [
    "### Problem 1: Inception Score (2pt)\n",
    "\n",
    "The formula for Inception Score is\n",
    "$$\n",
    "    \\text{IS} = \\exp \\bigl( \\mathbb{E}_{\\mathbf{x}} KL(p(y | \\mathbf{x}) || p(y)) \\bigr),\n",
    "$$\n",
    "\n",
    "where\n",
    "* $p(y | \\mathbf{x})$ is a pretrained classification model with labels $y$ (we will use [Inception V3 model](https://pytorch.org/vision/main/models/generated/torchvision.models.inception_v3.html));\n",
    "* $p(y) = \\int p(y | \\mathbf{x}) p(\\mathbf{x}) d \\mathbf{x}$ is a marginal distribution on labels.\n",
    "\n",
    "In order to calculate the **Inception** score we will use `InceptionV3` last layer activations (those before computing `Softmax`). The dimensionality of these activations is $1008$.\n",
    "\n",
    "Let initialize our classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8RaiX6Aa0k-"
   },
   "outputs": [],
   "source": [
    "DIMS = 1008\n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[DIMS]\n",
    "inception_model_act5 = InceptionV3([block_idx])\n",
    "if USE_CUDA:\n",
    "    inception_model_act5 = inception_model_act5.cuda()\n",
    "inception_model_act5.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WFYLKbea3QD"
   },
   "source": [
    "We need to get class probabilities from our classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjETtL1Ua3hO"
   },
   "outputs": [],
   "source": [
    "def get_inception_probs(x: torch.Tensor, model: object) -> np.ndarray:\n",
    "    # ====\n",
    "    # your code\n",
    "    # apply model and get probs (apply softmax)\n",
    "    \n",
    "    # ====\n",
    "    return probs.data.cpu().numpy()\n",
    "\n",
    "\n",
    "def test_get_inception_probs():\n",
    "    x = torch.zeros(size=(1, 3, 10, 10))\n",
    "    if USE_CUDA:\n",
    "        x = x.cuda()\n",
    "    probs = get_inception_probs(x, inception_model_act5)\n",
    "    true_probs = np.array(\n",
    "        [\n",
    "            0.00012616384,\n",
    "            0.00031305864,\n",
    "            0.00019984621,\n",
    "            0.00024997862,\n",
    "            0.00005619833,\n",
    "            0.00010180601,\n",
    "            0.00002303111,\n",
    "            0.0001946776,\n",
    "            0.0015921608,\n",
    "            0.000064336535,\n",
    "        ]\n",
    "    )\n",
    "    assert np.allclose(probs[0, :10], true_probs)\n",
    "\n",
    "\n",
    "test_get_inception_probs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYSh_Kcoa8Wq"
   },
   "outputs": [],
   "source": [
    "# this is a helper function that generates samples from the StyleGAN generator\n",
    "def generate_fake_images_stylegan(\n",
    "    sg_generator: object, n_samples: int, batch_size: int\n",
    ") -> np.ndarray:\n",
    "    fake_images = []\n",
    "    for i in range(n_samples // batch_size):\n",
    "        fake_samples = sg_generator.sample(batch_size).cpu().detach().numpy()\n",
    "        fake_images.extend(fake_samples)\n",
    "\n",
    "    fake_samples = sg_generator.sample(n_samples % batch_size).cpu().detach().numpy()\n",
    "    fake_images.extend(fake_samples)\n",
    "    return np.array(fake_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haDxeuSva-DE"
   },
   "source": [
    "It is the main function for getting Inception Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dldd3P3ma-Rt"
   },
   "outputs": [],
   "source": [
    "def get_inception_score(\n",
    "    generator: object,\n",
    "    inception_model: object,\n",
    "    n_samples: int,\n",
    "    batch_size: int = 32,\n",
    "    splits: int = 10,\n",
    ") -> np.ndarray:\n",
    "    if USE_CUDA:\n",
    "        generator = generator.cuda()\n",
    "        inception_model = inception_model.cuda()\n",
    "\n",
    "    generator.eval()\n",
    "    inception_model.eval()\n",
    "\n",
    "    fake_images = generate_fake_images_stylegan(generator, n_samples, batch_size)\n",
    "    loader = torch.utils.data.DataLoader(fake_images, batch_size=batch_size)\n",
    "\n",
    "    # ====\n",
    "    # your code\n",
    "    # get probs of size [n_samples x 1000] for the fake_samples\n",
    "\n",
    "    # ====\n",
    "\n",
    "    split_scores = []\n",
    "\n",
    "    for k in range(splits):\n",
    "        part = probs[k * (n_samples // splits) : (k + 1) * (n_samples // splits), :]\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) calculate p_y mean value of the current part\n",
    "        # 2) calculate KL (use could you entropy function from scipy)\n",
    "        # 3) exponentiate it\n",
    "        \n",
    "        # ====\n",
    "        split_scores.append(split_score)\n",
    "\n",
    "    return np.mean(split_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lQa2qDpbCAE"
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 1000\n",
    "BATCH_SIZE = 16\n",
    "SPLITS = 5\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "IS_stylegan_r1 = get_inception_score(\n",
    "    generator=stylegan_r1,\n",
    "    inception_model=inception_model_act5,\n",
    "    n_samples=N_SAMPLES,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    splits=SPLITS,\n",
    ")\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "IS_stylegan_wgangp = get_inception_score(\n",
    "    generator=stylegan_wgangp,\n",
    "    inception_model=inception_model_act5,\n",
    "    n_samples=N_SAMPLES,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    splits=SPLITS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iktQHlPbDn5"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(IS_stylegan_r1, 6.566, atol=0.1)\n",
    "assert np.allclose(IS_stylegan_wgangp, 6.63, atol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnzazethbI40"
   },
   "source": [
    "### Problem 2: Frechet Inception Distance (2pt)\n",
    "\n",
    "Now we will implement Frechet Inception Distance:\n",
    "\n",
    "$$\n",
    "\t\\text{FID} (\\pi, p) = \\| \\mathbf{m}_{\\pi} - \\mathbf{m}_{p}\\|_2^2 + \\text{Tr} \\left( \\boldsymbol{\\Sigma}_{\\pi} + \\boldsymbol{\\Sigma}_p - 2 \\sqrt{\\boldsymbol{\\Sigma}_{\\pi} \\boldsymbol{\\Sigma}_p} \\right)\n",
    "$$\n",
    "\n",
    "* Representations are the outputs of the intermediate layer from the pretrained classification model (we will use the activations of the last by one layer of `InceptionV3` (which have dimensionality $(2048, 1, 1)$), that's why the last two dimensions should be dropped before FID statistics calculation).\n",
    "* $\\mathbf{m}_{\\pi}$, $\\boldsymbol{\\Sigma}_{\\pi} $ are the mean vector and the covariance matrix of feature representations for samples from $\\pi(\\mathbf{x})$\n",
    "* $\\mathbf{m}_{p}$, $\\boldsymbol{\\Sigma}_p$ are the mean vector and the covariance matrix of feature representations for samples from $p(\\mathbf{x} | \\boldsymbol{\\theta})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkSozHiPbLn_"
   },
   "source": [
    "Let initialize our classification model which outputs last by one activations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XOpHVjNvbJKv"
   },
   "outputs": [],
   "source": [
    "DIMS = 2048\n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[DIMS]\n",
    "inception_model_act4 = InceptionV3([block_idx])\n",
    "if USE_CUDA:\n",
    "    inception_model_act4 = inception_model_act4.cuda()\n",
    "inception_model_act4.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ivz41HqxbOn7"
   },
   "source": [
    "Here we need samples from the ground truth distribution $\\pi(\\mathbf{x})$ (CIFAR10 images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHjFiT6kbOy2"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = load_dataset(\"cifar10\", flatten=False, binarize=False)\n",
    "visualize_images(train_data, \"CIFAR10 samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2giG0jJxbRWG"
   },
   "source": [
    "Let implement function to take square root of matrix (we need it for the formula above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_REm_GjfbRsX"
   },
   "outputs": [],
   "source": [
    "# this is a helper function, do not change\n",
    "def get_matrix_sqrt(x: torch.Tensor) -> torch.Tensor:\n",
    "    y = x.cpu().detach().numpy()\n",
    "    y = scipy.linalg.sqrtm(y)\n",
    "    if not np.isfinite(y).all():\n",
    "        print(\"bad!\")\n",
    "    return torch.Tensor(y.real, device=x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bO0qh5StbVwQ"
   },
   "source": [
    "Not let implement the function to calculate the distance (it is just the formula above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8R4Ed1v-bWJk"
   },
   "outputs": [],
   "source": [
    "def get_distance(\n",
    "    mu_x: torch.Tensor, mu_y: torch.Tensor, sigma_x: torch.Tensor, sigma_y: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    # ====\n",
    "    # your code\n",
    "    \n",
    "    # ====\n",
    "\n",
    "\n",
    "def test_get_distance():\n",
    "    mu_x = torch.ones(3)\n",
    "    mu_y = torch.ones(3) * 10\n",
    "    sigma_x = torch.eye(3) * 5\n",
    "    sigma_y = torch.eye(3) * 3\n",
    "    dist = get_distance(mu_x, mu_y, sigma_x, sigma_y)\n",
    "    assert np.isclose(dist, 243.7621)\n",
    "\n",
    "\n",
    "test_get_distance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pduycMPbaiP"
   },
   "source": [
    "Let implement the function which calculate intermediate representations for real and fake samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6NZymnDbazC"
   },
   "outputs": [],
   "source": [
    "def get_features(\n",
    "    generator: object,\n",
    "    inception_model: object,\n",
    "    loader: object,\n",
    "    n_samples: int,\n",
    "    batch_size: int,\n",
    ") -> tuple:\n",
    "    if USE_CUDA:\n",
    "        generator = generator.cuda()\n",
    "        inception_model.cuda()\n",
    "\n",
    "    generator.eval()\n",
    "    inception_model.eval()\n",
    "\n",
    "    fake_features_list = []\n",
    "    real_features_list = []\n",
    "    cur_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for real_samples in loader:\n",
    "            # real_samples = resize_tensor(real_samples, image_size)\n",
    "            if USE_CUDA:\n",
    "                real_samples = real_samples.cuda()\n",
    "            # ====\n",
    "            # your code\n",
    "            # get features of real samples\n",
    "            # drow the w and h dimensions of the obtained features\n",
    "            \n",
    "            # ====\n",
    "            # print(real_features.shape)\n",
    "            real_features_list.append(real_features)\n",
    "\n",
    "            fake_samples = generator.sample(len(real_samples), step=3)\n",
    "            # fake_samples = resize_tensor(fake_samples, image_size)\n",
    "            if USE_CUDA:\n",
    "                fake_samples = fake_samples.cuda()\n",
    "            # ====\n",
    "            # your code\n",
    "            # get features of fake samples\n",
    "            # drop the w and h dimensions of the the obtained features\n",
    "            \n",
    "            # ====\n",
    "            fake_features_list.append(fake_features)\n",
    "\n",
    "            cur_samples += len(real_samples)\n",
    "            if cur_samples >= n_samples:\n",
    "                break\n",
    "\n",
    "    fake_features_all = torch.cat(fake_features_list)\n",
    "    real_features_all = torch.cat(real_features_list)\n",
    "    return fake_features_all, real_features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uf4mQUnQbdPD"
   },
   "outputs": [],
   "source": [
    "# this is a helper function, do not change\n",
    "def calculate_stats(fake_features: torch.Tensor, real_features: torch.Tensor) -> tuple:\n",
    "    def get_covariance(features):\n",
    "        return torch.Tensor(np.cov(features.cpu().detach().numpy(), rowvar=False))\n",
    "\n",
    "    mu_fake = fake_features.mean(0)\n",
    "    mu_real = real_features.mean(0)\n",
    "    sigma_fake = get_covariance(fake_features)\n",
    "    sigma_real = get_covariance(real_features)\n",
    "    return mu_fake, mu_real, sigma_fake, sigma_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gm8Ec8TCbfdS"
   },
   "source": [
    "Now we are ready to implement the main function for getting FID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaJzbGZRbfuK"
   },
   "outputs": [],
   "source": [
    "def get_frechet_inception_distance(\n",
    "    generator: object,\n",
    "    inception_model: object,\n",
    "    loader: object,\n",
    "    n_samples: int,\n",
    "    batch_size: int,\n",
    ") -> torch.Tensor:\n",
    "    # ====\n",
    "    # your code\n",
    "    # 1) get features\n",
    "    # 2) calculate stats\n",
    "    # 3) get distance\n",
    "    \n",
    "    # ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oReQlX2KbmEa"
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 10000  # number of samples in the cifar10 test dataset\n",
    "BATCH_SIZE = 16  # samples per iteration\n",
    "\n",
    "gt_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "FID_r1 = get_frechet_inception_distance(\n",
    "    generator=stylegan_r1,\n",
    "    inception_model=inception_model_act4,\n",
    "    loader=gt_loader,\n",
    "    n_samples=N_SAMPLES,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "FID_wgangp = get_frechet_inception_distance(\n",
    "    generator=stylegan_wgangp,\n",
    "    inception_model=inception_model_act4,\n",
    "    loader=gt_loader,\n",
    "    n_samples=N_SAMPLES,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAkSy47nbnfS"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(FID_r1, 48.35, atol=0.2)\n",
    "assert np.allclose(FID_wgangp, 48.4, atol=0.2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0057c56e43504274858faf340424348c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "144b17bde62042ac86f4c3507240ac1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1f880ad04f534e08aad0a006a33ed646": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fca1a010dc84a2aadfc6b4e5f15d1f6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d013d0fa6ee74b4ead7dc4f66d55f77c",
      "value": "100%"
     }
    },
    "25a3dc242d10469abc5a211dbc0746ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb1bf34d7e344a5f9f459c0905548652",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_144b17bde62042ac86f4c3507240ac1e",
      "value": 7
     }
    },
    "2d52084a512f4055ad01a9afbfaffff5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f880ad04f534e08aad0a006a33ed646",
       "IPY_MODEL_25a3dc242d10469abc5a211dbc0746ca",
       "IPY_MODEL_a9b2b099d36149dda1a92bb1eece775b"
      ],
      "layout": "IPY_MODEL_d3b97e8914794f98bf81d84a2aadfe52"
     }
    },
    "518e7454eaa14f10ada3781a2401b622": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "639c32ab53164d7f9df57757b6e5c9c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "77b9f77796ab4344a23847d02e2087e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d0563bf68604b8b9614d4fe0a8f992b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_950787f7d6934287a86a0a38c57ae29d",
       "IPY_MODEL_89eb7c59a8e84fefa0db7f440f6848bb",
       "IPY_MODEL_8afb4f28944145c3b90bacb6cb3b6327"
      ],
      "layout": "IPY_MODEL_77b9f77796ab4344a23847d02e2087e0"
     }
    },
    "7d18d94ae32941f7adfab36d7b49f61e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89eb7c59a8e84fefa0db7f440f6848bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0057c56e43504274858faf340424348c",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_639c32ab53164d7f9df57757b6e5c9c2",
      "value": 3
     }
    },
    "8afb4f28944145c3b90bacb6cb3b6327": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a25e239d5cfd4c04a0569ee909df63e5",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bf5f3024f475431ca24c96f147255d75",
      "value": "â€‡3/20â€‡[02:34&lt;11:23,â€‡40.20s/it]"
     }
    },
    "8fca1a010dc84a2aadfc6b4e5f15d1f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "950787f7d6934287a86a0a38c57ae29d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f29ce587aa53499c9c9e9c589be8f320",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_518e7454eaa14f10ada3781a2401b622",
      "value": "â€‡15%"
     }
    },
    "a25e239d5cfd4c04a0569ee909df63e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9b2b099d36149dda1a92bb1eece775b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abc7b4bf2975473e8de753c032e6e212",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7d18d94ae32941f7adfab36d7b49f61e",
      "value": "â€‡7/7â€‡[03:02&lt;00:00,â€‡25.82s/it]"
     }
    },
    "abc7b4bf2975473e8de753c032e6e212": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf5f3024f475431ca24c96f147255d75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d013d0fa6ee74b4ead7dc4f66d55f77c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3b97e8914794f98bf81d84a2aadfe52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f29ce587aa53499c9c9e9c589be8f320": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb1bf34d7e344a5f9f459c0905548652": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
